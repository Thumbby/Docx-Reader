import streamlit as st
from langchain_community.document_loaders import Docx2txtLoader, DirectoryLoader, UnstructuredMarkdownLoader
from langchain_experimental.text_splitter import SemanticChunker
from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter
from langchain.globals import set_verbose, set_debug
from chain import retrieval_chain_init, eval_chain_init
from util import remove_think_chain
import os
import torch

torch.classes.__path__ = [os.path.join(torch.__path__[0], torch.classes.__file__)]
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE" 

set_debug(True)
def app():
    # App title
    st.title("ğŸ“„ éœ€æ±‚æ–‡æ¡£åˆ†æ")

    # Sidebar for instructions and settings
    with st.sidebar:
        st.header("ä½¿ç”¨æ­¥éª¤")
        st.markdown("""
        1. ä¸Šä¼ éœ€æ±‚æ–‡æ¡£(ä»¥docxæ ¼å¼).
        2. è¯¢é—®ä¸æ–‡æ¡£ç›¸å…³çš„é—®é¢˜.
        3. ç³»ç»Ÿä¼šæ ¹æ®æ–‡æ¡£å°è¯•å›ç­”æ‚¨çš„é—®é¢˜.
        """)

        st.header("è®¾ç½®")
        st.markdown("""
        - **Embedding Model**: HuggingFace
        - **Retriever Type**: Similarity Search
        - **LLM**: DeepSeek R1 1.5b(Ollama)
        """)

        # Main file uploader section
        st.header("ğŸ“ ä¸Šä¼ æ‚¨çš„éœ€æ±‚æ–‡æ¡£")
        uploaded_file = st.file_uploader("æ­¤å¤„ä¸Šä¼ æ‚¨çš„éœ€æ±‚æ–‡æ¡£", type="docx")

    if uploaded_file is not None:
        st.success("éœ€æ±‚æ–‡æ¡£ä¸Šä¼ æˆåŠŸï¼æ­£åœ¨è§£æ...")

        with open("temp.docx", "wb") as f:
            f.write(uploaded_file.getvalue())
            
        loader = Docx2txtLoader('temp.docx')
        docs = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=4096, chunk_overlap=256)
        documents = text_splitter.split_documents(docs)    
        
        # Initialize chain
        if "retrieval_chain" not in st.session_state:
            retrieval_chain = retrieval_chain_init(documents=documents)
            st.session_state.retrieval_chain = retrieval_chain
        else:
            retrieval_chain = st.session_state.retrieval_chain
        
        if "eval_chain" not in st.session_state:
            eval_chain = eval_chain_init()
            st.session_state.eval_chain = eval_chain
        else:
            eval_chain = st.session_state.eval_chain                 

        # Question input and response display
        st.header("â“ å¼€å§‹è¯¢é—®ä¸æ–‡æ¡£ç›¸å…³çš„é—®é¢˜")
        
        # Initialize chat history
        if "messages" not in st.session_state:
            st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½,æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"}]
            st.session_state.greeting = True

        # For each message in session state
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        last_message = st.session_state.messages[-1]
        
        if last_message["role"] == "assistant":
            # React to user input
            if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:"):
                # Display user message in chat message container
                with st.chat_message("user"):
                    st.markdown(prompt)
                # Add user message to chat history
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.spinner("æ€è€ƒä¸­ã€‚ã€‚ã€‚"):    
                    response = retrieval_chain.invoke({"input": prompt})                        
                    # Display assistant response in chat message container
                    with st.chat_message("assistant"):
                        st.markdown(response['answer'])
                    st.session_state.messages.append({"role": "assistant", "content": response['answer']})
                    
            # Show the evaluation button
            
            if st.session_state.greeting:
                st.session_state.greeting = False
            else:    
                if st.button("è¯„ä»·"):
                    st.session_state.show_eval = True
                
            if st.session_state.get("show_eval", False):
                with st.form(key="eval_form"):
                    evaluate_input = st.text_area("è¯·è¾“å…¥é¢„æœŸå›ç­”:")
                    submitted = st.form_submit_button("æäº¤è¯„ä»·")
                    if submitted:
                        # Get the final bot's reponse
                        ai_response = st.session_state.messages[-1]["content"]
                        with st.spinner("è¯„ä»·ä¸­..."):
                            score = eval_chain.invoke(input={
                                "ai_response": remove_think_chain(ai_response),
                                "human_response": evaluate_input
                            })
                            st.success(f"è¯„åˆ†ç»“æœ: {score}")
                        # Reset the evaluation button state
                        st.session_state.show_eval = False
                                
    else:
        st.info("è¯·å…ˆä¸Šä¼ æ–‡ä»¶")
    
if __name__ == "__main__":
    app()
